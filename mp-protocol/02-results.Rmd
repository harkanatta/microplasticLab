# Microplastic sampling and processing 2019 - Results

## Size

During the entire sampling period of 2019 a total of 283 particles were detected and measured. 230 particles were bigger than 350 µm. 50 particles were between 100-350 µm and only 3 particles were smaller than 100 µm. Size distribution of all detected particles are shown in the graph below. 

Due to the fact that the samples were analysed with the stereo microscope mostly large particles were observed. It is very likely that this picture would look different if a more sensitive analytical approach (like FTIR or Raman) would have been used. Some scientists which have been using more advanced analytical methods have shown that the abundance of microplastics increase with decreasing size. 

 
```{r pakkar, include=FALSE}
library(dplyr)
library(plyr)
library(magrittr)
library(DT)
library(data.table)
data <- read.csv('skjol/MPdata2019Karin.csv',header = T,dec = ".",na.strings = "")
data$blank <- ifelse(grepl("lank",data$Sample),"bl","mp")
litir=c("#E2FCFF", "#181818", "#FCFCD3")
```

```{r pieSize, echo=FALSE,fig.cap="Size distribution of the microplastic particles."}

#png(filename="PieSizeclass.png",12,7,"cm",pointsize=6,res=900)
pie(table(data$SizeClass),labels = table(data$SizeClass),col = litir)
legend("topright", c("Large (>350 μm)","Medium (100 μm - 350 μm)", "Small (<100 μm)"), fill = litir)
#box()
#dev.off()
```

## Colour

The most dominant colour was blue (64 particles) followed by transparent (57 particles) and black (56 particles). Color distribution, including less abundant colors, is shown in the graph below.

```{r pieColour, echo=FALSE, fig.cap="Color distribution of the microplastic particles."}
#png(filename="PieColour.png",12,7,"cm",pointsize=6,res=900)
pie(table(data$Colour),labels = paste(names(table(data$Colour)),table(data$Colour)),col = names(table(data$Colour)))
#box()
#dev.off()
```


## Particles per sampling trip

Sampling was carried out between April and October 2019 (total of 63 samples). Three samples were taken during each sampling trip (21 sampling trips). The average and standard deviation was calculated from each sampling trip and is shown in the graph below. 

Numbers of particles are very low which could be attributed to the analytical method (stereoscopic observation) which only allows us to detect bigger particles (see graph above). 

Mean particle abundance per sample ID was 1.2 (± 2.3).

As shown in the graph the standard deviation is very high which means there is big variability between the three samples. To improve this more samples could be taken. Another idea could be to sample a bigger volume of water to increase the number of particles. Instead of using a stereo microscope to detect the particles a more sensitive method could be used to be able to detect smaller particles and thus improve variability. 

Blanks during sampling were taken from July onwards and are represented as black bars in the barchart below. Number of particles in the blanks can be close to the number of particles found in the samples which makes it difficult to conclude on the real number of particle present in the samples. 



```{r barchartSD, echo=FALSE, fig.cap="Number of microplastic particles per sampling trip."}
data$blank <- ifelse(grepl("lank",data$Sample),"bl","mp")
DF <- ddply(data,.(Station,Sample,blank),summarise,N=table(Type))
# ddply(DF,.(blank),summarise,Mean=mean(N),SD=sd(N)) Mean and SD of all stations, both mp and blanks
DF <- ddply(DF,.(Station,blank),summarise,Mean=mean(N),SD=sd(N))
DF <- DF[!DF$Station==917,] #These samples were destroyed
DF <- DF[!is.na(DF$Station==TRUE),] #DF[is.na(DF$Station==FALSE),] doesn't give the same output...?

Mean <- tidyr::pivot_wider(DF[,-4],names_from = Station, values_from = Mean)
Mean <- Mean[,!grepl(" |,|[[:alpha:]]", colnames(Mean))]
SD <- tidyr::pivot_wider(DF[,-3],names_from = Station, values_from = SD)
SD <- SD[,!grepl(" |,|[[:alpha:]]", colnames(SD))]

myData <- rbind(Mean,SD)
myData <- as.data.frame(myData)


myData[3,myData[1,]== max(myData[1,],na.rm = T) ]
plotTop <- max(myData[1,],na.rm = T) +
  myData[3,  myData[1,] == max(myData[1,],na.rm = T)] * 2


litir=c("#E2FCFF", "#181818", "#FCFCD3")
#png(filename="Barchart.png",12,7,"cm",pointsize=6,res=900)
barCenters <- barplot(as.matrix(Mean),beside = T,ylim = c(0, plotTop),col = litir[1:2],ylab = "MP Particles", xlab = "sample ID", las=2)
segments(barCenters, as.matrix(Mean-SD) * 1, barCenters,
         as.matrix(Mean+SD) * 1, lwd = 1.5)

arrows(barCenters, as.matrix(Mean-SD) * 1, barCenters,
       as.matrix(Mean+SD) * 1, lwd = 1.5, angle = 90,
       code = 3, length = 0.05)


legend('topright',c("Samples","Blanks"),fill=litir)
box()
#dev.off()
```

## Particles per cubic meter per sampling week

From the number of particles found per sampling trip the number of particles per cubic meter was calculated and is shown in the graph 
As described above, the number of particles per cubic meters is very low with a mean of 0.9 (± 0.7) particles per cubic meter. 

```{r m3, echo=FALSE, fig.cap="Microplastic particles per cubic meter per sampling trip"}
DF <- ddply(data[data$blank!="bl",],.(Station,Sample, blank),summarise,N=table(Type))
DF <- ddply(DF,.(Station,Sample),summarise,N=sum(N))
DF$N <- DF$N/(3*1.4)
DF <- DF[DF$Station!=917,]
DF <- ddply(DF,.(Station),summarise,Mean=mean(N),SD=sd(N))
Mean <- tidyr::pivot_wider(DF[,-3],names_from = Station, values_from = Mean)
Mean <- Mean[,!grepl(" |,|[[:alpha:]]", colnames(Mean))]
SD <- tidyr::pivot_wider(DF[,-2],names_from = Station, values_from = SD)
SD <- SD[,!grepl(" |,|[[:alpha:]]", colnames(SD))]

myData <- rbind(Mean,SD)
myData <- as.data.frame(myData)
plotTop <- max(myData[1,],na.rm = T) +
  myData[2,  myData[1,] == max(myData[1,],na.rm = T)] * 2



#png(filename="MPperM3.png",12,7,"cm",pointsize=6,res=900)
barCenters <- barplot(as.matrix(Mean),beside = T,ylim = c(0, plotTop),ylab = expression(paste("MP/m"^"3")), xlab = "sample ID", las=2, col = litir[1])
segments(barCenters, as.matrix(Mean-SD) * 1, barCenters,
         as.matrix(Mean+SD) * 1, lwd = 1.5)

arrows(barCenters, as.matrix(Mean-SD) * 1, barCenters,
       as.matrix(Mean+SD) * 1, lwd = 1.5, angle = 90,
       code = 3, length = 0.05)

box()
#dev.off()


```


## Summary
In theory particle number should increase with decreasing particle size but that is not the case when analysing the samples with a stereo microscope.

Since the mean particle number was around 1.3 (± 2.3) per sampling trip and the mean number of particles found in the blank was around 0.5 (± 1.3) per sampling trip our findings are not very meaningful. 

<p style="color:red">The number of detected MP particles must be well above blank samples!!!</p>


## Improvements/Ideas

1. Start finding a purpose of the monitoring programme, and set its aims!
 + If the purpose of the monitoring is to detect long-term trends, of microplastics in the marine environment, sediments might be the most suitable matrix since it is the sink where most particles will be sequestered (collect where MPs are likely to accumulate)
 + If the purpose of the monitoring instead is to detect time trends of microplastic emissions from a point source, such as a wastewater treatment plant or an industry, sampling of the water surface or water column would ideally provide information on the single process or pathway. 

2. We need to change our sampling in order to increase the number of particles in each sample (e.g. by increasing sampling volume and decreasing mesh size or measuring smaller particles with the same mesh size, …). 
 + „Regardless of which method is applied, most important is to ensure that the samples contain a high enough number of particles and to take enough replicates to allow for statistical analysis of data. This is vital in order to compensate for uncertainty related to counting statistics and patchiness of microplastic particles within the confined sampled space (Karsson et al. 2018).“ 

3. Try to avoid sand in our samples to eliminate the density separation step (avoid sampling to close to the sea bed)

4. Our filters still seem to contain a lot of chitinous zooplankton carapaces after our digestion protocol with KOH and H2O2 
 + Try to digest with chitinase enzymes 
 + Another idea would be to use the Raman to check the chemical composition of the organic matter which is left on the filters to improve the digestion method (then we would be able to specifically target certain polymers like chitin, cellulose,.. and digest them accordingly).

5. Organic material needs to be digested further on our samples if automated spectroscopic analysis with Raman will be applied

6. In addition to internal blanks, recoveries of reference particles in different size fractions and external QA procedures should be included

## Other notes: 

* The abundance of microplastics, as for most other particles, increases exponentially with smaller sizes, and therefore all recent environmental risk assessment reports emphasize the role of smaller MP sizes
* Studies show that data from surface water only (like with manta net) does not provide a complete picture of the amount of microplastics in water.
* It should be emphasized that both the visual analyses with stereomicroscopy (to reveal the particle shape, colour and texture) and the interpretation of spectra from FTIR and Raman spectroscopy (to identify the polymer composition of the particles) require a well-trained staff if the results are to be reliable. 
* The more digestion steps are applied the higher the risk of contamination and the higher the risk of loss of particles in the samples
* When using ZnCl2: precipitation can form with high alkaline solutions (ZnOH2)
* ZnCl2: a larger number of non-plastic particles will float up to the surface, making the analysis of samples more difficult
* When working with ZnCl2: it is classified as toxic to humans and hazardous to the aquatic environment, and all the liquids and sediment need to be treated as chemical waste!!!
* The depth where water samples are being collected, or the sampling season can make a crucial difference in the amounts and types of organic material present in the samples -> affecting the selection of most suitable digestion methods.
* The requirements for sample quality and purity are higher when aiming to analyze smaller particles 

# Sampling and processing dates of 2019
```{r SamplingProcessingDates, echo=FALSE}
tafla <- read.csv("skjol/SamplingProcessingDates.csv",header = T,check.names=FALSE,fileEncoding="UTF-8-BOM")
names(tafla) <- c("Sample ID","Sampling Date","Processing Date", "Put on Filter")
tafla$`Sampling Date` <- as.Date(as.character(tafla$`Sampling Date`),"%d-%m-%Y")
tafla$`Processing Date` <- as.Date(as.character(tafla$`Processing Date`),"%d-%m-%Y")
tafla$`Put on Filter` <- as.Date(as.character(tafla$`Put on Filter`),"%d-%m-%Y")
#knitr::kable(tafla)
DT::datatable(tafla,caption = "Sampling and processing dates",rownames = F)
```


## Efficiency of digestion

Samples 901-906 could not be weighed as those samples were put onto a GF/C filter which seems to have lost weight after filtration. Hence samples 901-906 could not give us information about the digestion efficiency.
Samples 907-909 were put onto a membrane filter (0.22 um) and samples 910-922 were put onto the normal Nitrocellulose filters. Weight was taken from all filters after they had been dried at room temperature for several weeks. 
The median digestion efficiency was 92 % which means that 92 % of the organic matter present in the beginning was digested. The average digestion efficiency was at 88 %. 
The amount left behind on the filter after digestion correlates with the amount of organic matter originally present in the samples.
Digestion efficiency was below the average in samples 915, 916, 917, 918 and 920. Possibly because of high content of diatoms. 


```{r DigestionEfficiency, echo=FALSE}
tafla <- read.csv("skjol/DigestionEfficiency.csv",header = T,check.names=FALSE,fileEncoding="UTF-8-BOM")
tafla <- tafla[,-10]
names(tafla)[c(2,4,6,7,8,9)] <- c("Repl.","Debris after digest. [g] incl. tare", "Debris after digest. [g]","Debris before digest. [g]","% left after digest.","Digest. EFFCY [%]")
#knitr::kable(tafla)
tafla %>% 
  DT::datatable(caption = "Efficiency of digestion",rownames = F) %>% 
  DT::formatStyle(columns = colnames(tafla), fontSize = '80%')
```



```{r MyndDigestionEff, echo=FALSE,out.width='50%',fig.show='hold'}
tafla <- read.csv("skjol/DigestionEfficiency.csv",header = T,check.names=FALSE,fileEncoding="UTF-8-BOM")
tafla <- tafla[,-10]
myvars <- c(tafla$`Sample ID`) %in% c(901,902,903,904,905,906)
tafla <- tafla[!myvars,]
plot(tafla$`Debris after digestion [g]`,tafla$`Debris before digestion [g]`,type = 'n',ylab = "Before digestion [g]",xlab = "After digestion [g]")

library(dplyr)

tafla <- tafla %>%
    mutate(Colours = group_indices(., `Sample ID`))

N=max(tafla$Colours)
library(RColorBrewer)
myColors <-colorRampPalette(brewer.pal(9, "Set1"))(N)
#litir <- getPalette(N)

text(tafla$`Debris after digestion [g]`,tafla$`Debris before digestion [g]`, labels=tafla$`Sample ID`, cex= 0.7,col = myColors[tafla$Colours])
fit <- lm(tafla$`Debris before digestion [g]`~tafla$`Debris after digestion [g]`)
abline(a=coef(fit)[1], b=coef(fit)[2])

plot(tafla$`Debris before digestion [g]`,tafla$`Digestion efficiency [%]`,type = 'n',ylab = "Before digestion [g]",xlab = "Digestion efficiency [%]")
text(tafla$`Debris before digestion [g]`,tafla$`Digestion efficiency [%]`, labels=tafla$`Sample ID`, cex= 0.7,col = myColors[tafla$Colours])
fit <- lm(tafla$`Digestion efficiency [%]`~tafla$`Debris before digestion [g]`)
abline(a=coef(fit)[1], b=coef(fit)[2])
```


